---
title: The Basics for Graphical Models
layout: post
---

I have started to learn about the mathematical fundamentals behind graphical models, and so I am going to write some posts about what I am learning. Today I am going to start with a relatively simple introduction to the idea of graph networks and a review of probability. Many thanks to Daphne Koller and Nir Friedman’s excellent textbook for the education [1]. 

## Introduction to Probabilistic Graphical Models

Probabilistic graphical models (aka graph networks) are a way of encoding a “declarative representation” of a system [1]. They separate knowledge from reasoning. The representation contains information separately from algorithms that can act over the graph, so by building a graph, we allow ourselves to apply a whole group of algorithms that generally work over all kinds of graphs [1]. 

PGMs are really good for systems that have a lot of uncertainty. They also have structure that allows them to describe complex joint probability distributions in a compact way [1]. 

![Fig 1]({{ site.baseurl }}/images/2021-09-18-Graphs-fig1.png "Figure 1"){:width=75%}     
Figure 1 - Source [1]   

For example, this notation means that “$$X$$ is conditionally independent of $$Y$$ given $$Z$$”: 

$$X \perp \!\!\! \perp Y | Z$$

So for example, we can say that:

$$(congestion \perp \!\!\! \perp season | flu, hayfever)$$

which means that the random variable congestion is independent of the season given knowledge about the random variables flu and hayfever’s values. In other words, if I want to know the probability distribution of having congestion, and I know the values of the flu and hayfever random variables, then knowing about the season is no longer useful to me - i.e. knowing the season doesn’t tell me anything I didn’t already know at this point [1]. In mathematical terms: 

$$P(congestion | flu, hayfever, season) = P(congestion | flu, hayfever)$$

Another way to think about graphs is that they represent a set of factors that can be multiplied together to compute a probability distribution. This set of factors is a more compact way of representing the entire probability distribution [1]. As shown in Figure 1, we can write: 

$$P(S, F, H, C, M) = P(S) P(F | S) P(H | S) P(C | F, H) P(M | F)$$

Some key things to remember [1]: 

* **Bayesian networks use directed graphs** and **Markov networks use undirected graphs**.  

* The lack of an edge between 2 nodes indicates conditional independence between those two nodes. The presence of an edge does not necessarily indicate dependence, though!  

* A distribution, P, is positive if, $$\forall$$ events $$\alpha \in \mathcal{S}$$ such that $$\alpha \neq 0$$ we have $$P(\alpha) > 0$$. Note that by definition the probability of an event can be 0, so the distinction in stating that a distribution is positive means that no event can have a probability of zero.   

## Basic Probability


Events have a space of possible values, or outcomes. For rolling a dice, the result can be {1,2,3,4,5,6}. We can assign probabilities to each event [1]. 

There is a **frequentist vs subjective** debate over how to interpret the values of probabilities. The frequentist view sees probabilities as describing how frequently an event will occur. For example, it tells you how often a roll of the dice will result in rolling a 3. This doesn’t work so well for probabilities that describe, for example, the likelihood of snow today. It will either snow or not today - it is a single event. The subjective perspective thinks of probabilities instead describing how strongly we believe something is going to happen. For example, if the probability of snow today is 50%, then I think it is equally likely that it will or will not snow [1]. 

If I want to use my knowledge about the probability of one event to reason about the probability of another, I can use conditional probability. The formal definition of event $$\beta$$ happening given knowledge about event $$\alpha$$ is [1]: 

$$P(\beta | \alpha) = \frac{ P(\alpha \cap \beta) }{ P(\alpha) }$$

Conditional probabilities have a property known as the **chain rule**, which just rearranges the equation above [1]: 

$$P( \alpha \cap \beta) = P(\alpha) P(\beta | \alpha)$$

And in general this works over more events [1]:

$$P( \alpha_1 \cap . . . \cap \alpha_k) = P(\alpha_1) P(\alpha_2 | \alpha_1) . . . P(\alpha_k | \alpha_1 \cap . . . \cap \alpha_{k-1}) $$

We also have **Bayes Rule** [1]:

$$P(\alpha | \beta) = \frac{P(\beta | \alpha) P(\alpha)}{ P(\beta) }$$

Formally, **random variables describe properties of the outcome of an event**. For example, a student is an event and a random variable describing the student is their grade. It can be thought of as a function that maps the event to its attributes. Random variables can be discrete or continuous [1]. 

A **marginal distribution is the distribution over events that have random variable X**. P(X) is a marginal distribution over the random variable X. A **joint distribution is a distribution that gives the probabilities that events occur which have the properties described by all the random variables $$X_i$$** [1]. 

The joint distribution has to be consistent with the marginal distribution, that is [1]: 

$$P(x) = \sum_y P(x, y)$$

In fact, the term marginal refers to the fact that when we sum over all events $$y$$ to find $$P(x)$$, we write the sums in the margins of the probability table [1]. 

Conditional probability is not the same as marginal probability. Marginal probabilities tell us about our prior knowledge about the system before we know anything else about a specific event. The **conditional distribution represents what we know after learning information about the event** [1]. 

There is a notion of **independence** in probability. In general we expect that 

$$P(\alpha|\beta) \neq P(\alpha)$$

In other words, we expect that knowing $$\beta$$ changes our probability distribution over $$\alpha$$. But in some situations, learning $$\beta$$ can have no impact on $$P(\alpha)$$, i.e. 

$$P(\alpha | \beta) = P(\alpha)$$

Formally, an event $$\alpha$$ is independent of event $$\beta$$ in P, or 

$$P = (\alpha \perp \!\!\! \perp \beta) if P( \alpha | \beta) = P(\alpha) or if P(\beta) = 0$$

Another way to say this is that $$P(\alpha \cap \beta) = P(\alpha)P(\beta)$$ [1]. 

In the wild, it is more likely that we will see **conditional independence** than pure independence. That is, we are more likely to see cases where 2 events are independent given knowledge about an additional event. The formal definition for conditional independence is that event $$\alpha$$ is independent of event $$\beta$$ given event $$\gamma$$ in P such that [1]: 

$$P = (\alpha \perp \!\!\! \perp \beta | \gamma) \text{ if } P(\alpha | \beta \cap \gamma) = P(\alpha | \gamma) \text{ or if } P(\beta \intersect \gamma) = 0$$ 

Another way to look at it [1]: 

$$P = (\alpha \perp \!\!\! \perp \beta | \gamma) \text{ iff } P(\alpha \cap \beta | \gamma) = P(\alpha | \gamma) P(\beta | \gamma)$$

That’s all the basics for now. Next time I expect I will start writing about Markov Properties and possibly about different kinds of graphs. Thanks for reading!


## References

[1] Koller, D., Friedman, N. Probabilistic Graphical Models: Principles and Techniques. The MIT Press. Cambridge, Massachusetts. 2009. 
